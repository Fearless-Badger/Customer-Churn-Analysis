{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Dataset and Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The powershell in the assosiated GitHub repository allows for this notebook to download the datasetfor this project, provided you complete the \".env\" file with your kaggle API key, and file path.\n",
    "\n",
    "This script was written, so that this notebook may be run, tested, and modified either in the kaggle environment, or on a configured windows machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import warnings\n",
    "import math\n",
    "import dotenv\n",
    "import kagglehub\n",
    "import os\n",
    "import subprocess\n",
    "import ipywidgets\n",
    "\n",
    "\n",
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras as ks\n",
    "import matplotlib as mlt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "\n",
    "from scipy.stats import anderson, lognorm, probplot, shapiro\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "try:\n",
    "    dotenv.load_dotenv()\n",
    "except:\n",
    "    print(\"--Dotenv not loaded--\")\n",
    "\n",
    "\n",
    "# Check for Kaggle environment and set the file path\n",
    "if os.path.exists(\"/kaggle/input/churn-modelling/Churn_Modelling.csv\"):\n",
    "    # Kaggle\n",
    "    file_path = \"/kaggle/input/churn-modelling/Churn_Modelling.csv\"\n",
    "else:\n",
    "    # Local\n",
    "    file_path = (str((os.getenv(\"LOCAL_FILE_LOCATION\"))))\n",
    "\n",
    "# Load Dataset\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(\"Dataset Loaded Successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at : file_path\")\n",
    "    try:\n",
    "        print(\"Attempting to run download_data_ps1\")\n",
    "        path = os.getenv(\"SCRIPT_PATH\")\n",
    "        subprocess.run([\"powershell\", \"-ExecutionPolicy\", \"Bypass\", \"-File\", path],\n",
    "                       check = True, capture_output =  True, text = True)\n",
    "        print(\"Powershell Download Script Run Successfully. Now attempting to reload dataset...\")\n",
    "        df = pd.read_csv(file_path)\n",
    "        if df is not None and not df.empty:\n",
    "            print(\"Dataset Loaded Successfully\")\n",
    "        else:\n",
    "            print(\"Data not loaded\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error running powershell script: {e}\")\n",
    "        df = None\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "if df is not None:\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable is the last variable in this dataset. It is called \"Exited\". It is binary, where a 1 represents a customer closing thier account, and a 0 represents a retained customer.\n",
    "\n",
    "Let's preview the data in order to understand what we have to work with.\n",
    "\n",
    "First, I will drop the insignificant variables, which are the \"RowNumber\", \"CustomerId\", and \"Surname\" variables. They are arbitrary, and not useful for our algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM = 379\n",
    "\n",
    "X = df.iloc[:, 3:-1]\n",
    "Y = df.iloc[:,-1:]\n",
    "\n",
    "display(X.head())\n",
    "display(Y.head())\n",
    "\n",
    "display(f\"{X.shape=}\")\n",
    "display(f\"{Y.shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we have 10,000 observations for both the predictor and target variables.\n",
    "\n",
    "Now, we will check the dataset for any Null values and duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = X.copy()\n",
    "new_df['Exited'] = Y\n",
    "\n",
    "print(df.isna().sum(), '\\n')\n",
    "print(f\"Duplicate Count   \", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'\\?'\n",
    "null_df = df[\"Surname\"].astype(str).str.contains(pattern)\n",
    "mark_count = 0\n",
    "for val in null_df: \n",
    "    if val : mark_count += 1\n",
    "display(f\"The number of question marks appearing in the surname column is : {mark_count}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the \"Surname\" column, there are rare instances of \"?\" appearing. This indicates that there is missing or incomplete names. This is not concerning, because the \"Surname\" variable will be discarded when we build our model. \n",
    "\n",
    "Since there are no concerning NA values or duplicates, we can proceed with encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I will try to get a basic idea of what this dataset looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution\n",
    "\n",
    "First, we will examine the distributions of several variables in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(bins = 30, figsize=(22, 10), color = 'green');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this dataset is so large, it can be hard to tell exactly whether or not a distribution is normal. In order to proceed with my analysis, I will check for normality using the Anderson test.\n",
    "\n",
    "I picked the Anderson test for the creditscore variable since more weight is given to the tails of the distribution. This is Useful in this situation because of the sharp uptick at the right-tail of 'CreditScore'. \n",
    "\n",
    "Additionally, the Anderson test is suitable for large sets of observations. The Shapiro-Wilk test for normality would probably determine the 'CreditScore' variable to be normally distributed, since it is an unsuitable test for large inputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "    # Suppress warning. \n",
    "    # The warning states the shapiro wilk test is inaccurate for N > 5000.\n",
    "    # Current N is 10000\n",
    "    stat, p = shapiro(X['CreditScore'])\n",
    "    print(f\"Shapiro-Wilk Test: Stat = {round(stat, 3)}, p-val = {p}\\n\")\n",
    "\n",
    "\n",
    "result = anderson(X['CreditScore'])\n",
    "print(f\"Anderson Test: test-stat = {round(result.statistic, 3)}, Critical Values = {result.critical_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Anderson test statistic is 5.458. The critical values [0.576 0.656 0.787 0.918 1.092] correspond to significance levels [15%, 10%, 5%, 2.5% 1%]. Since the test statistic is greater than all critical values, we reject the null hypothesis. \n",
    "\n",
    "Compare this to the Shapiro-Wilk test. Since its p-value is less than 0.05, we would reject the null hypothesis and determine that the data is normally distributed. However, since the Shapiro test is not suitable for this dataset, we will disregard it.\n",
    "\n",
    "Therefore, the Anderson test determined that 'CreditScore' is not normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probplot(X['CreditScore'], dist = \"norm\", plot = plt)\n",
    "plt.title(\"Q-Q Plot of CreditScore\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probplot(X['EstimatedSalary'], dist = \"norm\", plot = plt)\n",
    "plt.title(\"Q-Q Plot of EstimatedSalary\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at the \"CreditScore\" Q-Q Plot, it is obviously not normally distributed. Also, I threw in the \"EstimatedSalary\" Q-Q plot. It follows a more uniform like distribution.\n",
    "\n",
    "We can visually inspect the previously produced histograms to determine that the \"Balance\" variable will behave simalarly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why use a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data is not normally distributed, we need a non-parametric model. Since the output is binary, we could use a multiple logistic regression model. Logistic regression does not require a normal distribution. However, it would require manual feature engineering to capture non-linear relationships, whereas a neural network is capable of automatically learning these patterns. This greatly cuts down on the amount of pre-processing work, since we only need to encode the categorical variables and scale all the features.\n",
    "\n",
    "The non-linear nature of this data, non-normal distribution, as well as the mix of categorical and quantitative data suggests that a neural network is a good model to build."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building The Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding\n",
    "Since we have two categorical variables, we must encode them before proceeding with the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjust_length = 17 # offset for output formatting\n",
    "\n",
    "for col in X:\n",
    "    print(f\"{col.ljust(adjust_length)} : {X[col].dtypes}\")\n",
    "print(f\"{(\"Exited\").ljust(adjust_length)} : {Y['Exited'].dtypes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"Gender\" variable will be encoded. A 0 represents the \"Female\" gender, a 1 represents the \"Male\" Gender.\n",
    "\n",
    "Similarly, the \"Geography\" variable will be encoded. Each geographical location will recieve its own binary column, with a 1 occurring in the column where the observation is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder = LabelEncoder()\n",
    "X['Gender'] = Encoder.fit_transform(X.iloc[:, 2]).astype(int)\n",
    "\n",
    "display((X.loc[:, 'CreditScore':'Gender']).iloc[0 : 5])\n",
    "\n",
    "\n",
    "print(f\"{str(X['Gender'].name)} : {X['Gender'].dtypes}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the \"Gender\" variable is represented as an integer.\n",
    "\n",
    "Next, we must encode the \"Geography\" variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X, columns=['Geography'], drop_first=True)\n",
    "\n",
    "# Cast geography variables to integers\n",
    "for col in X.columns:\n",
    "    if 'Geography_' in col:\n",
    "        X[col] = X[col].astype('int64')\n",
    "\n",
    "for col in X:\n",
    "    print(f\"{col.ljust(adjust_length)} : {X[col].dtypes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all of the variables are represented numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_df = X.copy()\n",
    "fin_df['Exited'] = Y\n",
    "\n",
    "display(fin_df.iloc[0 : 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "to-do: \n",
    "\n",
    "       - Perform basic EDA BEFORE encoding / scaling\n",
    "       - Scale features\n",
    "       - Perform EDA AFTER encoding/scaling\n",
    "       - Build neural network\n",
    "       - Optimize NN\n",
    "       - Analyze NN accuracy\n",
    "       - Review + Document\n",
    "       - Publish\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
